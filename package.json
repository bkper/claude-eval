{
  "name": "@bkper/claude-code-eval",
  "version": "1.0.0",
  "description": "Simple evaluation tool for Claude Code AI agent responses using LLM-as-a-judge methodology.",
  "type": "module",
  "main": "./dist/index.js",
  "bin": {
    "claude-eval": "./dist/bin/claude-eval.js"
  },
  "files": [
    "dist/",
    "README.md"
  ],
  "scripts": {
    "test": "jest",
    "test:watch": "jest --watch",
    "test:coverage": "jest --coverage",
    "build": "tsc",
    "clean": "rm -rf dist",
    "prepublishOnly": "npm run clean && npm run build",
    "dev": "tsc --watch --preserveWatchOutput",
    "dev:run": "node dist/bin/claude-eval.js"
  },
  "devDependencies": {
    "@types/bun": "latest",
    "@types/jest": "^30.0.0",
    "@types/node": "^24.3.0",
    "jest": "^30.0.5",
    "ts-jest": "^29.4.1"
  },
  "peerDependencies": {
    "typescript": "^5"
  },
  "dependencies": {
    "@anthropic-ai/claude-code": "^1.0.88",
    "chalk": "^5.6.0",
    "commander": "^14.0.0",
    "glob": "^11.0.3",
    "p-limit": "^7.1.0",
    "yaml": "^2.8.1"
  }
}